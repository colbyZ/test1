{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/AC 209A/STAT 121A Data Science: Homework 2\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>\n",
    "**Instructors: W. Pan, P. Protopapas, K. Rader**<br>\n",
    "**Due Date: ** Wednesday, September 21st, 2016 at 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the `IPython` notebook as well as the data file from Vocareum and complete locally.\n",
    "\n",
    "To submit your assignment, in Vocareum, upload (using the 'Upload' button on your Jupyter Dashboard) your solution to Vocareum as a single notebook with following file name format:\n",
    "\n",
    "`last_first_CourseNumber_HW2.ipynb`\n",
    "\n",
    "where `CourseNumber` is the course in which you're enrolled (CS 109a, Stats 121a, AC 209a). Submit your assignment in Vocareum using the 'Submit' button.\n",
    "\n",
    "**Avoid editing your file in Vocareum after uploading. If you need to make a change in a solution. Delete your old solution file from Vocareum and upload a new solution. Click submit only ONCE after verifying that you have uploaded the correct file. The assignment will CLOSE after you click the submit button.**\n",
    "\n",
    "\n",
    "Problems on homework assignments are equally weighted. The Challenge Question is required for AC 209A students and optional for all others. Student who complete the Challenge Problem as optional extra credit will receive +0.5% towards your final grade for each correct solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sklearn as sk\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "from sklearn.cross_validation import train_test_split as sk_split\n",
    "from sklearn.linear_model import LinearRegression as Lin_Reg\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 0: Basic Information\n",
    "\n",
    "Fill in your basic information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a): Your name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Zambalayev, Timur]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Course Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CSCI E-109a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c): Who did you work with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Inside the Models in Scikit-learn\n",
    "\n",
    "In this problem, we will be implementing K-Nearest Neighbour and simple linear regression for predicting a quantitative variable. We will compare the performance of our implementation with those of Scikit-learn (``sklearn``).\n",
    "\n",
    "The datasets required for this problem is in the ``dataset`` directory. Each file in the ``dataset`` directory contains a one-dimensional data set, with the first column containing the independent variable X, and the second column containing the dependent variable Y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a): Implement the models by hand\n",
    "In this part you **may not** use ``sklearn`` for any task.\n",
    "\n",
    "In the following, you may use ``numpy`` arrays instead of ``pandas`` dataframes.\n",
    "\n",
    "- Implement a function ``split``, which satifies:\n",
    "    - input: an ``nx2`` dataframe ``data``, a float ``m``\n",
    "    - return: an ``nx2`` dataframe ``train`` and an ``nx2`` dataframe ``test``, consisting of ``m`` percent and ``100 - m`` percent of the data, respectively.\n",
    "\n",
    "\n",
    "- Implement K-Nearest Neighbour for predicting a quantitative variable. That is, write a function, ``knn_predict``, that satisfies:\n",
    "    - input: an integer ``k``, an ``n x 2`` dataframe training set ``train``, an ``n x 1`` dataframe testing set ``test``\n",
    "    - return: an ``nx2`` dataframe, whose first column is that of ``test`` and whose second column is the predicted values.\n",
    "\n",
    "\n",
    "\n",
    "- Implement linear regression for predicting a quantitative variable. That is, write a function ``linear_reg_fit`` that satisfies:\n",
    "    - input: an ``nx2`` dataframe training set ``train``\n",
    "    - return: the coefficients of the linear regression model - a float ``slope`` and a float ``intercept``.\n",
    "    \n",
    "    \n",
    "- Write a function ``linear_reg_predict`` that satisfies:\n",
    "    - input: an ``nx1`` dataframe testing set ``test``, as well as the coefficients of the linear regression model\n",
    "    - return: an ``nx2`` dataframe, whose first column is that of ``test`` and whose second column is the predicted values.\n",
    "    \n",
    "    \n",
    "- Implement a function ``score`` that satisfies:\n",
    "    - input: an ``nx2`` dataframe ``predicted``, an ``nx2`` dataframe ``actual`` \n",
    "    - return: R^2 coefficient of the fit of the predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split\n",
    "\n",
    "\n",
    "def split(data, m):\n",
    "    test_size = 1 - m\n",
    "    length = len(data)\n",
    "\n",
    "    indices = list(data.index)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    test_length = int(round(test_size * length))\n",
    "    test_indices = indices[:test_length]\n",
    "    train_indices = indices[test_length:]\n",
    "\n",
    "    test = data.loc[test_indices]\n",
    "    train = data.loc[train_indices]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "# knn\n",
    "\n",
    "def distance(x1, x2):\n",
    "    return abs(x1 - x2)\n",
    "\n",
    "\n",
    "def find_best_neighbors_range(sorted_x_list, neighbors_range, test_x):\n",
    "    current_left_index = neighbors_range[0]\n",
    "    current_right_index = neighbors_range[1]\n",
    "    best_range = current_left_index, current_right_index\n",
    "    while current_right_index < len(sorted_x_list):\n",
    "        left_distance = distance(test_x, sorted_x_list[current_left_index])\n",
    "        right_distance = distance(test_x, sorted_x_list[current_right_index])\n",
    "        if left_distance <= right_distance:\n",
    "            break\n",
    "        best_range = current_left_index, current_right_index\n",
    "        current_left_index += 1\n",
    "        current_right_index += 1\n",
    "    if best_range[0] == neighbors_range[0]:\n",
    "        # we didn't find better neighbors on the right, so we'll search left\n",
    "        current_left_index = neighbors_range[0] - 1\n",
    "        current_right_index = neighbors_range[1] - 1\n",
    "        while current_left_index >= 0:\n",
    "            left_distance = distance(test_x, sorted_x_list[current_left_index])\n",
    "            right_distance = distance(test_x, sorted_x_list[current_right_index])\n",
    "            if left_distance >= right_distance:\n",
    "                break\n",
    "            best_range = current_left_index, current_right_index\n",
    "            current_left_index -= 1\n",
    "            current_right_index -= 1\n",
    "    return best_range\n",
    "\n",
    "\n",
    "def get_initial_range(k, insertion_index, length):\n",
    "    left_index = max(0, insertion_index - k / 2)\n",
    "    right_index = left_index + k\n",
    "    if right_index > length:\n",
    "        right_index = length\n",
    "        left_index = right_index - k\n",
    "    return left_index, right_index\n",
    "\n",
    "\n",
    "def find_nearest_neighbors(k, sorted_x_list, test_x):\n",
    "    insertion_index = bisect.bisect_left(sorted_x_list, test_x)\n",
    "    initial_range = get_initial_range(k, insertion_index, len(sorted_x_list))\n",
    "    return find_best_neighbors_range(sorted_x_list, initial_range, test_x)\n",
    "\n",
    "\n",
    "def knn_predict_one_point(k, sorted_x_list, sorted_y_list, test_x):\n",
    "    neighbors_range = find_nearest_neighbors(k, sorted_x_list, test_x)\n",
    "    total = 0.0\n",
    "    for index in range(neighbors_range[0], neighbors_range[1]):\n",
    "        total += sorted_y_list[index]\n",
    "    return total / k\n",
    "\n",
    "\n",
    "def knn_predict(k, train, test):\n",
    "    sorted_train = train.sort_values(by='x')\n",
    "    sorted_x_list = sorted_train['x'].tolist()\n",
    "    sorted_y_list = sorted_train['y'].tolist()\n",
    "    predicted_test = test.copy()\n",
    "\n",
    "    predicted_test['y'] = [knn_predict_one_point(k, sorted_x_list, sorted_y_list, row['x'])\n",
    "                           for index, row in test.iterrows()]\n",
    "    return predicted_test\n",
    "\n",
    "\n",
    "# linear regression\n",
    "\n",
    "def linear_reg_fit(train):\n",
    "    x_list = train['x'].tolist()\n",
    "    y_list = train['y'].tolist()\n",
    "\n",
    "    x_mean = np.mean(x_list)\n",
    "    y_mean = np.mean(y_list)\n",
    "\n",
    "    numerator_sum = 0.0\n",
    "    denominator_sum = 0.0\n",
    "    for x, y in izip(x_list, y_list):\n",
    "        x_diff = x - x_mean\n",
    "        numerator_sum += x_diff * (y - y_mean)\n",
    "        denominator_sum += x_diff ** 2\n",
    "\n",
    "    slope = numerator_sum / denominator_sum\n",
    "    intercept = y_mean - slope * x_mean\n",
    "    return slope, intercept\n",
    "\n",
    "\n",
    "def linear_reg_predict(test, slope, intercept):\n",
    "    predicted_test = test.copy()\n",
    "    predicted_test['y'] = [intercept + slope * row['x'] for index, row in test.iterrows()]\n",
    "    return predicted_test\n",
    "\n",
    "\n",
    "# score\n",
    "\n",
    "def score(predicted, actual):\n",
    "    rss = 0.0\n",
    "    tss = 0.0\n",
    "    actual_y_list = actual['y'].tolist()\n",
    "    actual_y_mean = np.mean(actual_y_list)\n",
    "    for predicted_value, actual_value in izip(predicted['y'].tolist(), actual_y_list):\n",
    "        rss += (actual_value - predicted_value) ** 2\n",
    "        tss += (actual_value - actual_y_mean) ** 2\n",
    "    return 1.0 - rss / tss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Compare with ``sklearn``\n",
    "\n",
    "- Load the contents of ``dataset_1_full.txt`` into a ``pandas`` dataframe, or ``numpy`` array. \n",
    "\n",
    "\n",
    "- Use your functions from Part (a) to split the data into training and testing sets (70-30). Evaluate how KNN and linear regression each perform on this dataset.\n",
    "\n",
    "\n",
    "- Use ``sklearn`` to split the data into training and testing sets (70-30). Use ``sklearn`` to evaluate how KNN and linear regression each perform on this dataset.\n",
    "\n",
    "\n",
    "- Use Python's ``time`` library to measure how well your implementations compare with that of ``sklearn``. What can you do (algorithmically or codewise) to make your implementation faster or more efficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our implementation\n",
      "KNN, k: 1, score: -0.396, time: 0.01\n",
      "KNN, k: 2, score: -0.027, time: 0.01\n",
      "KNN, k: 3, score: 0.205, time: 0.01\n",
      "KNN, k: 4, score: 0.244, time: 0.00\n",
      "KNN, k: 5, score: 0.266, time: 0.01\n",
      "KNN, k: 10, score: 0.338, time: 0.00\n",
      "KNN, k: 15, score: 0.342, time: 0.01\n",
      "KNN, k: 20, score: 0.382, time: 0.01\n",
      "KNN, k: 30, score: 0.417, time: 0.01\n",
      "KNN, k: 40, score: 0.402, time: 0.01\n",
      "KNN, k: 50, score: 0.421, time: 0.00\n",
      "KNN, k: 75, score: 0.417, time: 0.01\n",
      "KNN, k: 100, score: 0.413, time: 0.01\n",
      "KNN, k: 150, score: 0.397, time: 0.01\n",
      "KNN, k: 200, score: 0.364, time: 0.01\n",
      "KNN, k: 250, score: 0.284, time: 0.01\n",
      "KNN, k: 300, score: 0.181, time: 0.01\n",
      "KNN, k: 350, score: -0.002, time: 0.01\n",
      "linear regression, score: 0.418, time: 0.00\n",
      "\n",
      "sklearn implementation\n",
      "KNN, k: 1, score: -0.078, time: 0.00\n",
      "KNN, k: 2, score: 0.177, time: 0.00\n",
      "KNN, k: 3, score: 0.231, time: 0.00\n",
      "KNN, k: 4, score: 0.259, time: 0.00\n",
      "KNN, k: 5, score: 0.302, time: 0.00\n",
      "KNN, k: 10, score: 0.327, time: 0.00\n",
      "KNN, k: 15, score: 0.367, time: 0.00\n",
      "KNN, k: 20, score: 0.397, time: 0.00\n",
      "KNN, k: 30, score: 0.404, time: 0.00\n",
      "KNN, k: 40, score: 0.403, time: 0.00\n",
      "KNN, k: 50, score: 0.405, time: 0.00\n",
      "KNN, k: 75, score: 0.401, time: 0.00\n",
      "KNN, k: 100, score: 0.404, time: 0.00\n",
      "KNN, k: 150, score: 0.388, time: 0.00\n",
      "KNN, k: 200, score: 0.354, time: 0.00\n",
      "KNN, k: 250, score: 0.266, time: 0.00\n",
      "KNN, k: 300, score: 0.157, time: 0.00\n",
      "KNN, k: 350, score: -0.000, time: 0.00\n",
      "linear regression, score: 0.409, time: 0.00\n"
     ]
    }
   ],
   "source": [
    "import bisect\n",
    "from itertools import izip\n",
    "\n",
    "\n",
    "def generate_k_list():\n",
    "    k_list = list(range(1, 6))\n",
    "    k_list.extend(range(10, 21, 5))\n",
    "    k_list.extend(range(30, 51, 10))\n",
    "    k_list.extend(range(75, 101, 25))\n",
    "    k_list.extend(range(150, 351, 50))\n",
    "    return k_list\n",
    "\n",
    "\n",
    "def evaluate_our_implementation(df, k_list):\n",
    "    print 'our implementation'\n",
    "    train, test = split(df, 0.7)\n",
    "\n",
    "    test_x = test[['x']]\n",
    "    for k in k_list:\n",
    "        start = time.time()\n",
    "        predicted_test = knn_predict(k, train, test_x)\n",
    "        s = score(predicted_test, test)\n",
    "        elapsed_time = time.time() - start\n",
    "        print 'KNN, k: %d, score: %.3f, time: %.2f' % (k, s, elapsed_time)\n",
    "\n",
    "    start = time.time()\n",
    "    slope, intercept = linear_reg_fit(train)\n",
    "    predicted_test = linear_reg_predict(test_x, slope, intercept)\n",
    "    s = score(predicted_test, test)\n",
    "    elapsed_time = time.time() - start\n",
    "    print 'linear regression, score: %.3f, time: %.2f\\n' % (s, elapsed_time)\n",
    "\n",
    "\n",
    "def reshape(df, column_name):\n",
    "    return df[column_name].reshape((len(df), 1))\n",
    "\n",
    "\n",
    "def evaluate_sklearn_implementation(df, k_list):\n",
    "    print 'sklearn implementation'\n",
    "    train, test = sk_split(df, train_size=0.7)\n",
    "\n",
    "    x_train = reshape(train, 'x')\n",
    "    y_train = reshape(train, 'y')\n",
    "    x_test = reshape(test, 'x')\n",
    "    y_test = reshape(test, 'y')\n",
    "    for k in k_list:\n",
    "        start = time.time()\n",
    "        neighbors = KNN(n_neighbors=k)\n",
    "        neighbors.fit(x_train, y_train)\n",
    "        s = neighbors.score(x_test, y_test)\n",
    "        elapsed_time = time.time() - start\n",
    "        print 'KNN, k: %d, score: %.3f, time: %.2f' % (k, s, elapsed_time)\n",
    "\n",
    "    start = time.time()\n",
    "    regression = Lin_Reg()\n",
    "    regression.fit(x_train, y_train)\n",
    "    s = regression.score(x_test, y_test)\n",
    "    elapsed_time = time.time() - start\n",
    "    print 'linear regression, score: %.3f, time: %.2f' % (s, elapsed_time)\n",
    "\n",
    "\n",
    "def compare_with_sklearn():\n",
    "    np.random.seed(1090)\n",
    "\n",
    "    df = pd.read_csv('dataset/dataset_1_full.txt')\n",
    "    k_list = generate_k_list()\n",
    "\n",
    "    evaluate_our_implementation(df, k_list)\n",
    "    evaluate_sklearn_implementation(df, k_list)\n",
    "\n",
    "    \n",
    "compare_with_sklearn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***What can you do to make your implementation faster?***\n",
    "\n",
    "My current implmentation is as fast is sklearn's at least on this dataset. \n",
    "The optimizations I made in comparison to a possible naive implementation were:\n",
    "* I sorted the train dataframe by 'x' values so that it's easier/faster to locate k nearest neighbors. I used binary search to find the insertion point in the sorted array. Then I would start with a range of length k centered around that insertion point. Then I would try to improve that range by trying to move to the right and to the left.\n",
    "* Another optimization I made is I passed individual sorted 'x' and 'y' value lists for the train set so that not to do dataframe indexing inside a very nested loop. It improved the performance dramatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Handling Missing Data\n",
    "\n",
    "In this problem, we will be handling the problem of datasets with missing values. Clearly, we cannot simply remove entire rows or columns that contain missing values. In this problem, we explore two different ways to fill in missing values.\n",
    "\n",
    "The datasets required for this problem is in the ``dataset`` directory. Each file in the ``dataset`` directory contains a one-dimensional data set, with the first column containing the independent variable X, and the second column containing the dependent variable Y.\n",
    "\n",
    "The files ``dataset_1_missing.txt`` to ``dataset_6_missing.txt`` contains rows that are missing their y-values, where as ``dataset_1_full.txt`` to ``dataset_6_full.txt`` contain datasets with all y-values correctly filled in.\n",
    "\n",
    "In this problem, you **may not** use ``sklearn`` or build-in ``pandas`` functions to **directly fill in missing values**. Usage of these libraries/packages for related tasks is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a): Model Based Data Imputation\n",
    "\n",
    "- Describe in detail how predictive models for data (like KNN and simple linear regression) can be used to fill in missing values in a data set.\n",
    "\n",
    "\n",
    "- Implement your scheme. That is, write code (preferably a function ``fill`` or two functions ``fill_knn``, ``fill_lin_reg``), which takes an ``n x 2`` dataframe or array with values missing in the 2nd column and fills in these values using KNN and linear regression. \n",
    "\n",
    "\n",
    "- You need to, also, write code to evaluate the quality of the values you've filled in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Which Model is Better?\n",
    "\n",
    "- For datasets ``dataset_1_missing.txt`` to ``dataset_6_missing.txt``, compare the result of filling in the missing values using KNN and linear regression, using both the R^2 coefficient as well as data visualization (the correct y-values are contained in ``dataset_1_full.txt`` to ``dataset_6_full.txt``).. \n",
    "\n",
    "\n",
    "- Use your analysis to form conjectures regarding the conditions under which KNN performs better than linear regression, under which linear regression performs better than KNN and under which both perform equally (well or poorly). Explain in detail exactly what might cause each model to fail or perform well. \n",
    "\n",
    "\n",
    "\n",
    "- Using ``dataset_1_missing.txt``, explain the impact of the choice of $k$ on the performance of KNN. \n",
    "\n",
    "\n",
    "Use numerical analysis and data visualization to support every part of your argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Is the Best (Linear Model) Good Enough?\n",
    "\n",
    "In this problem, we will specifically look at conditions under which linear regression excels or fails.\n",
    "\n",
    "The datasets required for this problem is in the ``dataset`` directory. Each file in the ``dataset`` directory contains a one-dimensional data set, with the first column containing the independent variable X, and the second column containing the dependent variable Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a): Introduction to Residual Plots\n",
    "\n",
    "- Read ``dataset_1_full.txt``. Visualize the dataset and make some initial observations.\n",
    "\n",
    "\n",
    "- For this data set, what can you say about the following linear fits: \n",
    "\n",
    "    1. slope = 0.4, intercept = 0.2\n",
    "    2. slope = 0.4, intercept = 4\n",
    "    3. linear regression model\n",
    "\n",
    "\n",
    "- In each case, visualize the fit, compute the residuals, and make a residual plot of predicted values along with  residuals, as well as a residual histogram. What do these plots reveal?  \n",
    "\n",
    "\n",
    "- Calculate the R^2 coefficient for all three fits. What do the erors reveal? How do they compare to the residual plots?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): What do Residual Plots Reveal?\n",
    "\n",
    "- Read datasets ``dataset_2_full.txt`` through ``dataset_6_full.txt``. In each case, visualize the fit, compute the residuals, and make a residual plot of predicted values along with  residuals, as well as a residual histogram. What do these plots reveal about the fit of the model? \n",
    "\n",
    "\n",
    "- Calculate the R^2 coefficient each fit. What do the erors reveal? How do they compare to the residual plots?\n",
    "\n",
    "\n",
    "- Based on your analysis, form conjectures regarding the precise relationship between the residual plots and the fit of the linear regression model. Conjecture on the precise conditions under which linear regression model is an appropriate model for a given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Problem: Combining Random Variables\n",
    "\n",
    "This problem, we explore the distirbution of random variables that result from combining other random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a): Adding Two Uniformly Distributed Variables\n",
    "\n",
    "Consider the independent random variables $X\\sim U(0, 1)$ and $Y\\sim U(0, 1)$. Let $Z$ be the random variable $Z = X + Y$. \n",
    "\n",
    "What is the distribution of $Z$ (give the pdf for Z)? You should fully explain and support your conlusion. \n",
    "\n",
    "**Hint:** your solution can be a combination of experimentation, empirical evidence and/or algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Adding Multiple Uniformly Distributed Variables\n",
    "\n",
    "Consider three independent random variables $X_1, X_2, X_3 \\sim U(0, 1)$. Let $Z$ be the random variable $Z = X_1 + X_2 + X_3$. \n",
    "\n",
    "What is the distribution of $Z$? What if you add 10 or 12 independent (standard) uniformly distributed variables? Conjecture on the distribution of \n",
    "$$\n",
    "Z = \\lim_{n\\to \\infty} \\sum_{i=1}^n X_i\n",
    "$$\n",
    "where $\\left\\{X_i \\right\\}$ are independent (standard) uniformly distributed variables.\n",
    "\n",
    "**Hint:** your solution can be a combination of experimentation, empirical evidence and/or algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c): Combining Normally Distributed Variables\n",
    "\n",
    "Consider the independent random variables $X\\sim \\mathcal{N}(0, 1)$ and $Y\\sim \\mathcal{N}(0, 1)$. Let $Z$ be the random variable $Z = X + Y$. \n",
    "\n",
    "What is the distribution of $Z$ (give the pdf for Z)? You should fully explain and support your conlusion. \n",
    "\n",
    "**Hint:** use properties of expected value and some experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (d): Product of Normally Distributed Variables\n",
    "\n",
    "Is the product of two normally distributed variables a normally distributed variable? You should fully explain and support your conlusion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
